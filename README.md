# ğŸ“š KnowledgeGPT

> ğŸ¤– Your AI-powered knowledge assistant that brings documents to life

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”® RAG Powered  â”‚  âš¡ Easy Setup  â”‚  ğŸ§  Claude AI  â”‚  ğŸ¨ Streamlit  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Version:** 1.0.0 | **Python:** 3.9+ | **License:** MIT | **Framework:** LangChain 0.1.4

---

## ğŸš€ Introduction

**KnowledgeGPT** transforms how you interact with your documents. Using cutting-edge Retrieval-Augmented Generation (RAG) technology, it allows you to have natural conversations with your PDFs, Word documents, and text files. Simply upload your documents and start asking questions in plain language to receive accurate, context-aware responses based on your content.

> ğŸ’¡ **Perfect for researchers, students, professionals, and knowledge workers who need to quickly extract insights from large documents.**

<details>
<summary>ğŸ’« Why KnowledgeGPT?</summary>

- **â±ï¸ Save Hours of Reading**: Extract key information without reading entire documents
- **ğŸ” Discover Hidden Insights**: Uncover connections across multiple documents
- **ğŸ“– Enhance Learning**: Interact with complex material through natural conversation
- **âš¡ Boost Productivity**: Get answers to specific questions instantly
- **ğŸ”’ Privacy First**: Your documents never leave your machine - no data harvesting

</details>

---

## âœ¨ Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“„ Document Support    â”‚   ğŸ§  RAG Architecture    â”‚   ğŸ’¬ Memory System      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ PDF files             â”‚  â€¢ FAISS vector search   â”‚  â€¢ Short-term session   â”‚
â”‚  â€¢ Word documents        â”‚  â€¢ Smart retrieval       â”‚  â€¢ Long-term persistent â”‚
â”‚  â€¢ Text files            â”‚  â€¢ Fast indexing         â”‚  â€¢ Context awareness    â”‚
â”‚  â€¢ Markdown              â”‚  â€¢ Semantic matching     â”‚  â€¢ Natural flow         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“„ Universal Document Support
Seamlessly process PDFs, Word documents, TXT files, and Markdown with intelligent text extraction that preserves document structure.

### ğŸ§  Advanced RAG Architecture
Utilizes state-of-the-art retrieval techniques with FAISS vector search for lightning-fast, highly relevant document retrieval.

### ğŸ’¬ Conversational Memory
Maintains context across your conversation with both short-term session memory and long-term persistent memory for more natural interactions.

### ğŸ” Source Attribution
Every answer includes references to the specific documents and sections used, ensuring transparency and verifiability.

### âš¡ Real-time Responses
Streaming response generation provides immediate feedback with token-by-token display for a fluid chat experience.

### ğŸ› ï¸ Customizable Experience
Fine-tune retrieval parameters, model behavior, and interface settings to match your specific use case and preferences.

---

## ğŸ› ï¸ Technology Stack

```
    ğŸ¤–              ğŸ”—              ğŸ”              ğŸŒ              ğŸ“Š
  Claude AI      LangChain        FAISS        Streamlit         Qwen
  â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Advanced        RAG           Vector          Web           Embeddings
  reasoning      framework       search       interface
```

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

```
âœ“ Python 3.9 or higher
âœ“ API keys for Claude AI
âœ“ API keys for OpenAI/Qwen Embeddings
```

### ğŸ’» Installation

<details>
<summary>ğŸ“¦ Step-by-step instructions</summary>

**1ï¸âƒ£ Clone the repository**

```bash
git clone https://github.com/yourusername/knowledgegpt.git
cd knowledgegpt
```

**2ï¸âƒ£ Install dependencies**

```bash
pip install -r requirements.txt
```

**3ï¸âƒ£ Set up environment variables**

Create a `.env` file in the root directory:

```env
ANTHROPIC_LLM_API_KEY=your_anthropic_api_key
OPENAI_EMBEDDING_API_KEY=your_openai_api_key
```

**4ï¸âƒ£ Run the application**

```bash
streamlit run app/web_chatbot.py
```

**5ï¸âƒ£ Access the web interface**

Open your browser and go to `http://localhost:8501`

</details>

<details>
<summary>ğŸ³ Docker installation (alternative)</summary>

```bash
# Build the Docker image
docker build -t knowledgegpt .

# Run the container
docker run -p 8501:8501 --env-file .env knowledgegpt
```

</details>

---

## ğŸ“š Usage Guide

```
Step 1              Step 2              Step 3
  ğŸ“¤                  â“                  âœ…
Upload           Ask Questions      Get Insights
Documents        in Natural         with Sources
                 Language
```

### 1ï¸âƒ£ ğŸ“¤ Upload Documents
Click "Upload New Document" in the sidebar and select your files (PDF, DOCX, TXT, MD).

### 2ï¸âƒ£ â“ Ask Questions
Type your questions in natural language in the chat input field at the bottom.

### 3ï¸âƒ£ âœ… Get Insights
Receive detailed answers with reference sources from your documents.

---

### ğŸ’¡ Example Questions

```
â” "What are the key points in the executive summary?"
â” "Summarize the methodology section in bullet points"
â” "Compare the financial results from 2023 to 2024"
â” "What did the author say about climate change impacts?"
â” "Extract all tables from the document and format them nicely"
```

---

## ğŸ§© Project Architecture

```
knowledgegpt/
â”‚
â”œâ”€â”€ ğŸ“± app/                          # Application layer
â”‚   â””â”€â”€ web_chatbot.py               # Streamlit web interface
â”‚
â”œâ”€â”€ ğŸ’» src/                          # Core source code
â”‚   â”œâ”€â”€ ğŸ”— chains/                   # LangChain chains
â”‚   â”‚   â””â”€â”€ faiss_conversational_chain.py
â”‚   â”œâ”€â”€ ğŸ¤– chat_model/               # LLM integration
â”‚   â”œâ”€â”€ ğŸ“Š embedding/                # Vector embeddings
â”‚   â”œâ”€â”€ ğŸ“‚ loaders/                  # Document loaders
â”‚   â”œâ”€â”€ ğŸ§  memory/                   # Conversation memory
â”‚   â”‚   â””â”€â”€ long_term_memory.py
â”‚   â”œâ”€â”€ ğŸ“ prompts/                  # Prompt templates
â”‚   â”œâ”€â”€ ğŸ”§ utils/                    # Utility functions
â”‚   â”œâ”€â”€ ğŸ—„ï¸ vectorstores/            # Vector store implementations
â”‚   â””â”€â”€ âš™ï¸ config.py                # Configuration
â”‚
â”œâ”€â”€ ğŸ’¾ data/                         # Data directory
â”‚   â”œâ”€â”€ documents/                   # Document storage
â”‚   â”œâ”€â”€ faiss_index/                 # FAISS vector indices
â”‚   â””â”€â”€ long_term_memory/            # Persistent memory storage
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencies
â””â”€â”€ ğŸ“– README.md                     # Documentation
```

---

## âš™ï¸ Advanced Configuration

Fine-tune KnowledgeGPT by adjusting parameters in `src/config.py`:

<details>
<summary>ğŸ”§ Available Configuration Options</summary>

```python
# ğŸ¤– LLM configuration
ANTHROPIC_MODEL_NAME = "claude-3-7-sonnet"  # Model selection
TEMPERATURE = 0.7                           # Response creativity (0.0-1.0)
MAX_TOKENS = 2000                           # Maximum response length

# ğŸ” Retrieval parameters
TOP_K = 5                                   # Number of chunks to retrieve
SIMILARITY_THRESHOLD = 0.7                  # Minimum relevance score

# âœ‚ï¸ Chunking parameters
CHUNK_SIZE = 1000                           # Text chunk size
CHUNK_OVERLAP = 200                         # Overlap between chunks

# ğŸ§  Memory configuration
MAX_HISTORY_LENGTH = 20                     # Conversation turns to remember
```

</details>

---

## ğŸ”® Roadmap

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   âœ… Current Features   â”‚    ğŸ”œ Coming Soon       â”‚    ğŸš€ Future Plans      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Multi-document        â”‚ â€¢ Multi-language        â”‚ â€¢ Image/chart analysis  â”‚
â”‚ â€¢ Source attribution    â”‚ â€¢ Document comparison   â”‚ â€¢ Data visualization    â”‚
â”‚ â€¢ Conversational memory â”‚ â€¢ Custom knowledge base â”‚ â€¢ Mobile application    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ FAQ

<details>
<summary><b>ğŸ“„ What types of documents can I use?</b></summary>

KnowledgeGPT supports PDF, Word documents (.docx), plain text files (.txt), and Markdown (.md) files.
</details>

<details>
<summary><b>ğŸ”’ Is my data secure?</b></summary>

Yes! Your documents are processed locally on your machine. Only the necessary chunks are sent to the LLM API for generating responses, and no data is stored on external servers.
</details>

<details>
<summary><b>ğŸ¯ How accurate are the responses?</b></summary>

KnowledgeGPT uses advanced RAG techniques to retrieve the most relevant information from your documents. The accuracy depends on the quality of your documents and the specificity of your questions. The system always provides source references so you can verify the information.
</details>

<details>
<summary><b>ğŸ”„ Can I use a different LLM?</b></summary>

Yes, the system is designed to be model-agnostic. You can modify the configuration to use other LLMs like GPT-4, Llama, or Mistral by adjusting the settings in the config file.
</details>

<details>
<summary><b>ğŸ“Š How many documents can I upload?</b></summary>

There's no hard limit on the number of documents, but performance may decrease with very large document collections. For optimal performance, we recommend keeping your knowledge base under 1,000 pages total.
</details>

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

```
1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create your feature branch (git checkout -b feature/amazing-feature)
3. ğŸ’¾ Commit your changes (git commit -m 'Add some amazing feature')
4. ğŸ“¤ Push to the branch (git push origin feature/amazing-feature)
5. ğŸ‰ Open a Pull Request
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the LICENSE file for details.

---

## ğŸ™ Acknowledgements

- ğŸ”— [LangChain](https://python.langchain.com/) - Amazing RAG framework
- ğŸ¤– [Anthropic Claude](https://www.anthropic.com/claude) - Powerful LLM
- ğŸ” [FAISS](https://github.com/facebookresearch/faiss) - Efficient vector search
- ğŸ¨ [Streamlit](https://streamlit.io/) - Easy-to-use web framework
- ğŸ“Š [Qwen](https://github.com/QwenLM/Qwen) - High-quality embeddings

---

<div align="center">

**Built with ğŸ’™ for the knowledge seekers of the world**

[ğŸ› Report Bug](https://github.com/yourusername/knowledgegpt/issues) â€¢ [âœ¨ Request Feature](https://github.com/yourusername/knowledgegpt/issues) â€¢ [â­ Star Us](https://github.com/yourusername/knowledgegpt/stargazers)

</div>
